# VLA_PAPERS

| 算法简称       | 论文题目 (ArXiv 链接)                                                                                  | GitHub 代码链接                                              |
|---------------|------------------------------------------------------------------------------------------------------|-------------------------------------------------------------|
| **VoxPoser**  | [VoxPoser: Composable 3D Value Maps for Robotic Manipulation with Language Models](https://arxiv.org/abs/2307.05973)  | https://github.com/huangwl18/VoxPoser                        |
| **ReKEP**     | [ReKep: Spatio-Temporal Reasoning of Relational Keypoint Constraints for Robotic Manipulation](https://arxiv.org/abs/2409.01652)  | https://github.com/rekep-robot/ReKep                        |
| **AnyGrasp**  | [AnyGrasp: Robust and Efficient Grasp Perception in Spatial and Temporal Domains](https://arxiv.org/abs/2212.08333) | https://github.com/graspnet/anygrasp_sdk                    |
| **ACT**       | [Learning Fine‑Grained Bimanual Manipulation with Low‑Cost Hardware](https://arxiv.org/abs/2304.13705) | https://github.com/tonyzhaozh/act                            |
| **Mobile ALOHA** | [Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low‑Cost Whole‑Body Teleoperation](https://arxiv.org/abs/2401.02117) | https://github.com/MarkFzp/mobile-aloha                     |
| **RoboAgent** (MT‑ACT) | [RoboAgent: Generalization and Efficiency in Robot Manipulation via Semantic Augmentations and Action Chunking](https://arxiv.org/abs/2309.01918)  | https://github.com/robopen/roboagent                        |
| **Diffusion Policy (DP)** | [Diffusion Policy: Visuomotor Policy Learning via Action Diffusion](https://arxiv.org/abs/2303.04137)  | https://github.com/real-stanford/diffusion_policy           |
| **3DP (DP3)** | [3D Diffusion Policy: Generalizable Visuomotor Control with 3D Representations](https://arxiv.org/abs/2403.03954) | https://github.com/YanjieZe/3D-Diffusion-Policy              |
| **OpenVLA**   | [OpenVLA: An Open‑Source Vision‑Language‑Action Model](https://arxiv.org/abs/2406.09246) | https://github.com/openvla/openvla                           |
| **OpenVLA‑OFT** | [Fine‑Tuning Vision‑Language‑Action Models: Optimizing Speed and Success](https://arxiv.org/abs/2502.19645)| https://openvla-oft.github.io/                             |
| **π₀**        | [A Vision‑Language‑Action Flow Model for General Robot Control (π₀)](https://arxiv.org/abs/2410.24164) | https://github.com/lucidrains/pi-zero-pytorch               |
| **π₀‑FAST**   | [Efficient Action Tokenization for Vision‑Language‑Action Models (FAST)](https://arxiv.org/abs/2501.09747)  | https://github.com/Physical-Intelligence/openpi              |
| **RDT‑1B**    | [RDT‑1B: a Diffusion Foundation Model for Bimanual Manipulation](https://arxiv.org/abs/2410.07864) | https://github.com/robotics-diffusion-transformer/rdt-1b    |

> *注：GitHub 链接如未找到官方仓库，则列出社区复刻或项目主页。欢迎补充或纠正。*
